{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step II of Proposed Method :\n",
    "* weakly supervised fine-tuning of the MLP trained at Step I \n",
    "* MIL training on the 279 cases (containing >250K tiles)\n",
    "* add pretrained MLP on top of ResNet50 features of each tile obtaining **prediction per tile**\n",
    "* aggregate tile predictions under the naive assumption **patient_prediction =  max(tiles_prediction)**\n",
    "* trained using Adam optimizer with lr=0.001\n",
    "* minimized weighted BCE loss with regard to class imbalance ratio \n",
    "* proposed a combined loss as a regularization strategy i.e imposing sparsity on the vector of local tile predictions:\n",
    "\n",
    "**L = BCE(global_pred) + alpha * L1_norm(tiles_proba)/n_tiles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Step-II-of-Proposed-Method-:\" data-toc-modified-id=\"Step-II-of-Proposed-Method-:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Step II of Proposed Method :</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Read-Data\" data-toc-modified-id=\"Read-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Read Data</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Train</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-k-fold-CV-on-training-set\" data-toc-modified-id=\"Train-k-fold-CV-on-training-set-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Train k-fold CV on training set</a></span></li><li><span><a href=\"#Plot-train-loss\" data-toc-modified-id=\"Plot-train-loss-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Plot train loss</a></span></li><li><span><a href=\"#Retrain-ensemble-on-all-training-set\" data-toc-modified-id=\"Retrain-ensemble-on-all-training-set-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Retrain ensemble on all training set</a></span></li></ul></li><li><span><a href=\"#Predict-test-set\" data-toc-modified-id=\"Predict-test-set-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Predict test set</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.3.1\n",
      "tf version:  2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"keras version: \", keras.__version__)\n",
    "print(\"tf version: \", tf.__version__)\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import optimizers \n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ensembles = 1\n",
    "n_splits = 5\n",
    "batch_size = 10\n",
    "lr = 1e-3\n",
    "epochs = 30\n",
    "\n",
    "use_pre_trained_mlp = True\n",
    "fc_layer_size = [100,10]\n",
    "dropout_rate = 0.5\n",
    "\n",
    "alpha = 0         # Loss = BCE(global_pred) + alpha * ||tiles_pred||1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../chowder_data')\n",
    "\n",
    "train_dir = data_dir / \"train_input\" / \"resnet_features\"\n",
    "test_dir = data_dir / \"test_input\"  / \"resnet_features\"\n",
    "\n",
    "train_output_filename = data_dir / \"train_output.csv\"\n",
    "\n",
    "df = pd.read_csv(train_output_filename)\n",
    "\n",
    "# Get the filenames for train\n",
    "#filenames_train = [train_dir / \"{}.npy\".format(idx) for idx in train_output[\"ID\"]]\n",
    "filenames_train = sorted(train_dir.glob(\"*.npy\"))\n",
    "for filename in filenames_train:\n",
    "    assert filename.is_file(), filename\n",
    "\n",
    "# Get the labels\n",
    "labels_train = df[\"Target\"].values\n",
    "\n",
    "assert len(filenames_train) == len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Path'] = filenames_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tiles_count'] = get_number_tiles(filenames_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Path</th>\n",
       "      <th>tiles_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>../chowder_data/train_input/resnet_features/ID...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Target                                               Path  tiles_count\n",
       "0   1       0  ../chowder_data/train_input/resnet_features/ID...         1000\n",
       "1   2       0  ../chowder_data/train_input/resnet_features/ID...         1000\n",
       "2   3       0  ../chowder_data/train_input/resnet_features/ID...         1000\n",
       "3   5       0  ../chowder_data/train_input/resnet_features/ID...          839\n",
       "4   6       0  ../chowder_data/train_input/resnet_features/ID...         1000\n",
       "5   7       0  ../chowder_data/train_input/resnet_features/ID...          999\n",
       "6   8       1  ../chowder_data/train_input/resnet_features/ID...         1000\n",
       "7   9       0  ../chowder_data/train_input/resnet_features/ID...         1000\n",
       "8  10       1  ../chowder_data/train_input/resnet_features/ID...          442\n",
       "9  11       0  ../chowder_data/train_input/resnet_features/ID...         1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    if use_pre_trained_mlp:\n",
    "        # load pre trained MLP\n",
    "        base_model = keras.models.load_model(\"base_model.h5\")\n",
    "    else:\n",
    "        # build MLP\n",
    "        tile = Input((2048,))\n",
    "        x = tile\n",
    "        for fc in fc_layer_size:\n",
    "            x = Dense(fc, activation='sigmoid')(x)\n",
    "            if dropout_rate > 0:\n",
    "                x = Dropout(dropout_rate)(x)\n",
    "        tile_prediction = Dense(1, activation='sigmoid')(x)\n",
    "        base_model = Model(inputs=tile, outputs=tile_prediction)\n",
    "    \n",
    "    input = Input(shape=(None, 2048))\n",
    "    local_predictions = TimeDistributed(base_model)(input)\n",
    "\n",
    "    global_prediction = GlobalMaxPool1D()(local_predictions)\n",
    "    model = Model(inputs=input, outputs=global_prediction)\n",
    "    \n",
    "    def my_loss_fn(y_true, y_pred):\n",
    "        local_predictions_l1 = tf.reduce_sum(local_predictions) / tf.cast(tf.size(local_predictions), tf.float32)\n",
    "        bce = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        return (bce + alpha * local_predictions_l1)\n",
    "\n",
    "    model.compile(optimizers.Adam(lr),\n",
    "                  loss=my_loss_fn, #'binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train k-fold CV on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(df.Target.values), y=df.Target.values)\n",
    "print(\"class weights\", class_weights)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "history_folds = []\n",
    "aucs = []\n",
    "\n",
    "for fold, (i_train, i_val) in enumerate(kf.split(df, df.Target)):\n",
    "    \n",
    "    print(\"Fold {} / {}\".format(fold+1, n_splits))\n",
    "    \n",
    "    # get data\n",
    "\n",
    "    df_train = df.iloc[i_train]\n",
    "    df_val = df.iloc[i_val]\n",
    "    \n",
    "    train_generator = batch_generator(df_train, batch_size)\n",
    "    val_generator = batch_generator(df_val, 1)\n",
    "    \n",
    "    train_steps = int(np.ceil(len(df_train)/batch_size))\n",
    "    val_steps = len(df_val)\n",
    "    \n",
    "    # build model\n",
    "    model = get_model()\n",
    "    \n",
    "    # train model\n",
    "    history = model.fit(\n",
    "                            train_generator,\n",
    "                            steps_per_epoch=train_steps,\n",
    "                            validation_data=val_generator,\n",
    "                            validation_steps=val_steps,\n",
    "                            epochs=epochs,\n",
    "                            verbose=0,\n",
    "                            class_weight=dict(enumerate(class_weights))\n",
    "                        )\n",
    "    \n",
    "    auc = model.evaluate(val_generator, steps=val_steps)[-1]\n",
    "    print(\"Val AUC = {:.3f}\".format(auc))\n",
    "    aucs.append(auc)\n",
    "    history_folds.append(history.history)\n",
    "    \n",
    "aucs = np.array(aucs)\n",
    "print(\"***** Val AUC : {:.3f} +/- {:.3f} ***** \".format(aucs.mean(), aucs.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for fold in range(len(history_folds)):\n",
    "    plt.plot(history_folds[fold]['loss'], '--')\n",
    "    plt.plot(history_folds[fold]['val_loss'], label='fold {}'.format(fold))\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain ensemble on all training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ensemble_models = []\n",
    "\n",
    "for e in range(n_ensembles):\n",
    "    print(\"Ensemble\", e)\n",
    "    generator = batch_generator(df, batch_size)\n",
    "    steps = int(np.ceil(len(df)/batch_size))\n",
    "    model = get_model()\n",
    "    model.fit(generator,\n",
    "              steps_per_epoch=steps,\n",
    "              epochs=epochs,\n",
    "              verbose=0,\n",
    "              class_weight=dict(enumerate(class_weights)))\n",
    "    ensemble_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filenames of test set samples\n",
    "filenames_test = sorted(test_dir.glob(\"*.npy\"))\n",
    "for filename in filenames_test:\n",
    "    assert filename.is_file(), filename\n",
    "# extract image IDs from filenames\n",
    "ids = [re.search(\"ID_(.+?).npy\", str(filename)).group(1) for filename in filenames_test]\n",
    "# populate DF with IDs\n",
    "df_test = pd.DataFrame({'ID':ids, 'Path': filenames_test })\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions of all trained models in the ensemble\n",
    "ensemble_prediction = []\n",
    "for model in ensemble_models:\n",
    "    # initialize data generator and compute number of steps\n",
    "    test_generator = test_batch_generator(df_test)\n",
    "    test_steps = len(df_test)\n",
    "    # predict\n",
    "    ensemble_prediction.append(model.predict(test_generator, steps=test_steps))\n",
    "ensemble_prediction = np.stack(ensemble_prediction, axis=0)\n",
    "print(ensemble_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final prediction as the average vote between ensembles\n",
    "# and populate DF with the predictions\n",
    "df_test['Target'] = ensemble_prediction.mean(axis=0)\n",
    "# clean DF and save\n",
    "df_test.set_index(\"ID\", inplace=True)\n",
    "df_test = df_test.drop(columns=['Path'])\n",
    "df_test.to_csv(data_dir / \"preds_test_maxpool_pretrained={}_alpha={}.csv\".format(use_pre_trained_mlp, alpha))\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot label ditribution (sanity check: expected bimodal distribution)\n",
    "plt.figure()\n",
    "_ = plt.hist(df_test['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_preds = sorted((data_dir/'preds').glob(\"*.csv\"))\n",
    "plt.figure()\n",
    "for f in filenames_preds:\n",
    "    plt.hist(pd.read_csv(f)['Target'], alpha=0.2, label=f.stem)\n",
    "    print(f.stem, pd.read_csv(f)['Target'].min(), pd.read_csv(f)['Target'].max())\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
